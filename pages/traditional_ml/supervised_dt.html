<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src='https://kit.fontawesome.com/a076d05399.js'></script>
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
        <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> -->
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
        <!-- begin SEO -->
        <title>Decision Tree - Forough Shirin Abkenar</title>
        <meta property="og:locale" content="en-US">
        <meta property="og:site_name" content="Decision Tree">
        <meta property="og:title" content="Decision Tree">
        <link rel="canonical" href="https://foroughshirinabkenar.github.io/mysite/genAI.html">
        <meta property="og:url" content="https://foroughshirinabkenar.github.io/mysite/genAI.html">
        <meta property="og:description" content="Decision Tree">
        <script async="" src="//www.google-analytics.com/analytics.js"></script>
        <script type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Aritra Ghosh", "url" : "https://foroughshirinabkenar.github.io", "sameAs" : null } </script>
        <!-- end SEO -->
        <!-- http://t.co/dKP3o1e -->
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script>
        <!-- For all browsers -->
        <link rel="stylesheet" href="https://foroughshirinabkenar.github.io/mysite/assets/css/main.css">
        <meta http-equiv="cleartype" content="on">
        <!-- start custom head snippets -->
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="https://foroughshirinabkenar.github.io/mysite/assets/css/academicons.css">
        <script type="text/x-mathjax-config;executed=true"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
        <script type="text/x-mathjax-config;executed=true"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML" async=""></script>
        <!-- end custom head snippets -->
        <style id="fit-vids-style">.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style>
        <script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
            .MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
            .MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
            .MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
            .MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
        </style>
        <style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
                #MathJax_About.MathJax_MousePost {outline: none}
                .MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
                .MathJax_MenuItem {padding: 2px 2em; background: transparent}
                .MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
                .MathJax_MenuActive .MathJax_MenuArrow {color: white}
                .MathJax_MenuArrow.RTL {left: .5em; right: auto}
                .MathJax_MenuCheck {position: absolute; left: .7em}
                .MathJax_MenuCheck.RTL {right: .7em; left: auto}
                .MathJax_MenuRadioCheck {position: absolute; left: 1em}
                .MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
                .MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
                .MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
                .MathJax_MenuDisabled {color: GrayText}
                .MathJax_MenuActive {background-color: Highlight; color: HighlightText}
                .MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
                .MathJax_ContextMenu:focus {outline: none}
                .MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
                #MathJax_AboutClose {top: .2em; right: .2em}
                .MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
                .MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
                .MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
                .MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
                .MathJax_MenuClose:hover span {background-color: #CCC!important}
                .MathJax_MenuClose:hover:focus {outline: none}
        </style>
        <style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
        </style>
        <style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
            .MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
        </style>
        <style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
            #MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
            #MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
            #MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
        </style>
        <style type="text/css">.MathJax_Preview {color: #888}
            #MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
            #MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
            .MathJax_Error {color: #CC0000; font-style: italic}
        </style>
        <style type="text/css">.MJXp-script {font-size: .8em}
            .MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
            .MJXp-bold {font-weight: bold}
            .MJXp-italic {font-style: italic}
            .MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-largeop {font-size: 150%}
            .MJXp-largeop.MJXp-int {vertical-align: -.2em}
            .MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
            .MJXp-display {display: block; text-align: center; margin: 1em 0}
            .MJXp-math span {display: inline-block}
            .MJXp-box {display: block!important; text-align: center}
            .MJXp-box:after {content: " "}
            .MJXp-rule {display: block!important; margin-top: .1em}
            .MJXp-char {display: block!important}
            .MJXp-mo {margin: 0 .15em}
            .MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
            .MJXp-denom {display: inline-table!important; width: 100%}
            .MJXp-denom > * {display: table-row!important}
            .MJXp-surd {vertical-align: top}
            .MJXp-surd > * {display: block!important}
            .MJXp-script-box > *  {display: table!important; height: 50%}
            .MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
            .MJXp-script-box > *:last-child > * {vertical-align: bottom}
            .MJXp-script-box > * > * > * {display: block!important}
            .MJXp-mphantom {visibility: hidden}
            .MJXp-munderover {display: inline-table!important}
            .MJXp-over {display: inline-block!important; text-align: center}
            .MJXp-over > * {display: block!important}
            .MJXp-munderover > * {display: table-row!important}
            .MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
            .MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
            .MJXp-mtr {display: table-row!important}
            .MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
            .MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
            .MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
            .MJXp-mlabeledtr {display: table-row!important}
            .MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
            .MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
            .MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
            .MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
            .MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
            .MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
            .MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
            .MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
            .MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
            .MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
            .MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
            .MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
            .MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
            .MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
        </style>
        <style>
          .table-wrap {overflow-x: auto;}
          #tab-eval-finetune {border-collapse: collapse; width: 100%; min-width: 720px; text-align: center;}
          #tab-eval-finetune caption {caption-side: top; font-weight: 600; margin-bottom: 0.5rem;}
          #tab-eval-finetune th,
          #tab-eval-finetune td {border: 1px solid #444; padding: 0.5rem 0.6rem; vertical-align: middle;}
          #tab-eval-finetune thead th {background: #f5f5f5;}
          /* Add cline effect under BLEU + ROUGE headers only */
          #tab-eval-finetune thead .cline-row th {border-top: none;}
          /* Draw a thick line under the second header row except the first column (PPL) */
          #tab-eval-finetune thead .cline-row th:not(:first-child) {border-bottom: 2px solid #000;}
        </style>
        <style>
          body {
            font-size: 16px;
            font-family: Arial, sans-serif;
          }
          h1 {
            font-size: 24;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
          h2 {
            font-size: 22;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
          h3 {
            font-size: 20px;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
          h4 {
            font-size: 18px;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
        </style>
    </head>

    <body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
        <div id="MathJax_Message" style="display: none;"></div>
        <!--[if lt IE 9]>
            <div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
        <![endif]-->
        <div class="masthead">
            <div class="masthead__inner-wrap">
                <div class="masthead__menu">
                    <nav id="site-nav" class="greedy-nav"> 
                        <button class="hidden" count="0"><div class="navicon"></div></button>
                        <ul class="visible-links">
                            <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://foroughshirinabkenar.github.io/mysite/index.html">Forough Shirin Abkenar</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/publications.html">Publications</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/bio.html">Bio</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/traditional_ml.html">Traditional ML</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/genAI.html">Gen AI Projects</a></li>
                        </ul>
                        <ul class="hidden-links hidden"></ul>
                    </nav>
                </div>
            </div>
        </div>
        <div id="main" role="main">
            <div class="sidebar sticky">
                <div itemscope="" itemtype="http://schema.org/Person">
                    <div class="author__avatar"> <img src="https://foroughshirinabkenar.github.io/mysite/images/profile.jpeg" class="author__avatar" alt="Forough Shirin Abkenar"></div>
                    <div class="author__content">
                        <h3 class="author__name">Forough Shirin Abkenar</h3>
                        <p class="author__bio">Ph.D., Electrical Engineering and Computer Science</p>
                    </div>
                    <div class="author__urls-wrapper">
                        <button class="btn btn--inverse">Follow</button>
                        <ul class="author__urls social-icons">
                            <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> California, USA</li>
                            <li><a href="mailto:fshirina@uci.edu" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i> Email</a></li>
                            <!--<li><a href="https://foroughshirinabkenar.wixsite.com/mysite" target="_blank"><i class="fab fa-wix" aria-hidden="true"></i> Wix</a></li>
                            <li><a href="https://iasl.ics.uci.edu/people/forough-shirin-abkenar/" target="_blank">UCI</a></li>
                            <li><a href="https://www.researchgate.net/profile/Forough_Shirin_Abkenar2" target="_blank"><i class="fab fa-researchgate" style='color:green' aria-hidden="true"></i> ResearchGate</a></li>
                            -->
                            <li><a href="https://www.linkedin.com/in/forough-s-1460b2198" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
                            <li><a href="https://github.com/foroughshirinabkenar" target="_blank"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
                            <li><a href="https://scholar.google.com/citations?user=TQ0vI44AAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i> Google Scholar</a></li>
                            <li><a href="https://ieeexplore.ieee.org/author/37086113585" target="_blank"><img src="https://foroughshirinabkenar.github.io/mysite/images/logos/IEEE.jpg" style="width: 3em;"> IEEE</a></li>
                            <li><a href="https://www.webofscience.com/wos/author/record/AAA-7697-2019" target="_blank"><img src="https://foroughshirinabkenar.github.io/mysite/images/logos/wos.png" style="width: 1em;"> Web of Science</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <article class="page" itemscope="" itemtype="http://schema.org/CreativeWork">
                <meta itemprop="headline" content="Decision Tree">
                <meta itemprop="description" content="Decision Tree">
                <div class="page__inner-wrap">
                    <header>
                        <h1 class="page__title" itemprop="headline">Decision Tree</h1>
                        <p align="justify">
                          A decision tree is an algorithm that recursively splits a dataset 
                            into subsets based on its features. The splitting criterion is 
                            typically determined using one of two metrics, i.e., 
                            <em>Information Gain (IG)</em> or <em>Gini Index</em>.

                            <ul>
                                <li>
                                    <p align="justify">
                                        <b>Information Gain:</b> IG is based on 
                                        <em>entropy</em>, which quantifies the 
                                        level of uncertainty or randomness in 
                                        the information being processed. IG 
                                        measures the reduction in entropy that 
                                        results from partitioning the dataset 
                                        according to a given feature. 
                                        To calculate the IG, we have
                                    </p>

                                    <p>
                                        \[
                                            \text{IG(D, A)} = \text{H(D)} - \text{H(D|A)},
                                        \]
                                    </p>

                                    <p align="justify">
                                        where D and A are the dataset and the feature, 
                                        respectively; H(D) represents the entropy of the 
                                        dataset; and H(D|A) shows the entropy of the dataset 
                                        w.r.t. the feature A (conditional entropy). The entropy 
                                        of a set S, where \(\{\text{A, D}\in\text{S}\}\) is given by
                                    </p>

                                    <p>
                                        \[
                                            \text{H(S)} = -\sum_{x\in S}p_{i}(x)\log(p_{i}(x)),
                                        \]
                                    </p>

                                    <p align="justify">
                                        where \(p_{i}\) is proportion of the \(i\)-th class in the set.
                                    </p>
                                </li>
                                <li>
                                    <p align="justify">
                                        <b>Gini Index:</b> Gini Index measures the probability that a 
                                        randomly chosen instance would be misclassified if it were 
                                        labeled according to the class distribution in the dataset. 
                                        Therefore, we have
                                    </p>

                                    <p>
                                        \[
                                            \text{H(S)} = 1 -\sum_{x\in S}p^{2}_{i}(x),
                                        \]
                                    </p>

                                    <p align="justify">
                                        where \(p_{i}\) is the probability of an instance belonging to class
                                        \(i\).
                                    </p>
                                </li>
                            </ul>
                        </p>

                        <p align="justify">
                            Overall, an IG–based model aims to maximize IG, while a Gini Index–based 
                            model aims to minimize the Gini value. IG is generally more suitable for 
                            imbalanced datasets, whereas the Gini Index is computationally simpler 
                            to implement.
                        </p>

                        <h2>Numerical Example</h2>
                        <p align="justify">
                            Given the data in Table 1, we perform the decision tree algorithm based on IG.

                            <table>
                                <caption>Table 1. Example Data for Decision Tree [2].</caption>
                                <thead>
                                  <tr>
                                    <th>Neighborhood</th>
                                    <th>No. of Rooms</th>
                                    <th>Affordable</th>
                                  </tr>
                                </thead>
                                <tbody>
                                  <tr>
                                    <td>West</td>
                                    <td>3</td>
                                    <td>Yes</td>
                                  </tr>
                                  <tr>
                                    <td>West</td>
                                    <td>5</td>
                                    <td>Yes</td>
                                  </tr>
                                  <tr>
                                    <td>West</td>
                                    <td>2</td>
                                    <td>Yes</td>
                                  </tr>
                                  <tr>
                                    <td>East</td>
                                    <td>3</td>
                                    <td>Yes</td>
                                  </tr>
                                  <tr>
                                    <td>East</td>
                                    <td>4</td>
                                    <td>Yes</td>
                                  </tr>
                                  <tr>
                                    <td>East</td>
                                    <td>6</td>
                                    <td>No</td>
                                  </tr>
                                  <tr>
                                    <td>East</td>
                                    <td>5</td>
                                    <td>No</td>
                                  </tr>
                                  <tr>
                                    <td>East</td>
                                    <td>2</td>
                                    <td>Yes</td>
                                  </tr>
                                </tbody>
                            </table>
                        </p>

                        <p>
                            First, we calculate the entropy of the data w.r.t. the labels (i.e., 
                            "Affordable" feature). Considering 6 data points labeled as "Yes" and 
                            2 data points labeled as "No" (see Fig. 1), the probabilities of "Yes" 
                            (\(p_{yes}\)) and "No" (\(p_{no}\)) are equal to \(p_{yes} = 6/8\) and 
                            \(p_{no} = 2/8\). Therefore, we have

                            <figure style="display: flex; flex-direction: column; align-items: center;">
                                <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/supervised_learning/dt_num_root.png"
                                    style="max-width: 20%; height: auto;"
                                  />
                                <figcaption>Fig. 1: Root node for decision tree algorithm.</figcaption>
                            </figure>
                        </p>

                        <p>
                            \[
                                \begin{split}
                                    \text{H(D)} =~& -p(Y=yes)\log(p(Y=yes)) -\\ & ~~~p(Y=no)\log(p(Y=no))\\
                                    =~& -\frac{6}{8}\log(\frac{6}{8}) - \frac{2}{8}\log(\frac{2}{8}) = 0.81
                                \end{split}
                            \]
                        </p>

                        <p align="justify">
                            In the next step, the data samples must be split based on the features, i.e., 
                            "Neighborhood" and "No. of Rooms", separately. The corresponding IG needs to 
                            be calculated for each feature, and the feature with the highest IG is 
                            chosen as the splitting feature. Thus, we have
                        </p>

                        <p>
                            \[
                                \begin{split}
                                    \text{H(D|Neighborhood)} =~& \text{H(D|Neighborhood=West)} + \text{H(D|Neighborhood=East)}\\
                                    =~&\text{H(Y=yes|Neighborhood=West) + H(Y=no|Neighborhood=West)} +\\
                                    & \text{H(Y=yes|Neighborhood=East) + H(Y=no|Neighborhood=East)}\\
                                    =~&-\frac{3}{8}\left(\frac{3}{3}\log(1) + \frac{0}{3}\log(0)\right) - \frac{5}{8}\left(\frac{3}{5}\log(\frac{3}{5}) + \frac{2}{5}\log(\frac{2}{5})\right) = 0.61
                                \end{split}
                            \]
                        </p>

                        <p>
                            \[
                                \begin{split}
                                    \text{H(D|No. of Rooms)} =~& \text{H(D|No. of Rooms<5)} + \text{H(D|No. of Rooms}\geq 5)\\
                                    =~&\text{H(Y=yes|No. of Rooms<5) + H(Y=no|No. of Rooms<5)} +\\
                                    & \text{H(Y=yes|No. of Rooms}\geq 5) + \text{H(Y=no|No. of Rooms}\geq 5)\\
                                    =~&-\frac{5}{8}\left(\frac{5}{5}\log(1) + \frac{0}{5}\log(0)\right) - \frac{3}{8}\left(\frac{1}{2}\log(\frac{1}{2}) + \frac{2}{3}\log(\frac{2}{3})\right) = 0.35
                                \end{split}
                            \]
                        </p>

                        <p align="justify">
                            Therefore, IG for each group is calculated as
                        </p>

                        <p>
                            \[
                                \begin{split}
                                    & \text{IG(D|Neighborhood)} = 0.81 - 0.61 = 0.2\\
                                    & \text{IG(D|No. of Rooms)} = 0.81 - 0.35 = 0.46
                                \end{split}
                            \]
                        </p>

                        <p align="justify">
                            Since \(\text{IG(D|No. of Rooms)} > \text{IG(D|Neighborhood)}\), 
                            we choose "No. of Rooms" as the splitting feature.

                            <figure style="display: flex; flex-direction: column; align-items: center;">
                                <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/supervised_learning/dt_num_ig1.png"
                                    style="max-width: 40%; height: auto;"
                                  />
                                <figcaption>Fig. 2: Decision tree after first splitting.</figcaption>
                            </figure>
                        </p>

                        <p align="justify">
                            In the next round, since the entropy of the left child of the tree is zero 
                            (all samples belong to the same class, i.e., "Yes"), we split the right 
                            child of the tree w.r.t. the "Neighborhood". Therefore, we have

                            <figure style="display: flex; flex-direction: column; align-items: center;">
                                <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/supervised_learning/dt_num_ig2.png"
                                    style="max-width: 40%; height: auto;"
                                  />
                                <figcaption>Fig. 2: Decision tree after second splitting.</figcaption>
                            </figure>
                        </p>

                        
                        
                         <h2>Implementation</h2>
                          <p align="justify">
                            The machine learning decision tree model in Python was developed from 
                              scratch following the guidelines provided in [2]. The complete 
                            implementation script is available on 
                            <a href="https://github.com/foroughshirinabkenar/traditional_ml_tutorial/blob/main/decision_tree_scratch.ipynb" target="_blank">
                              Decision Tree from Scratch</a>.
                          </p>

                          <h3>Classifier</h3>
                          <p align="justify">
                              We developed a decision tree classifier for the <b>Breast Cancer</b> dataset 
                              using the built-in functions provided in <em>scikit-learn</em> [1] in Python. 
                              The following screenshot illustrates the training process of the 
                              classifier. the model was imported from 
                              sklearn.<span style="color: blue;">tree</span>.
                              Moreover, we applied <b>Grid Search Cross-Validation</b> to identify 
                              the optimal hyperparameters of the model. In this process, we defined ranges 
                              for various convergence criteria, such as <em>max_depth</em>, 
                              <em>min_samples_split</em>, <em>min_samples_leaf</em>, and the splitting 
                              criterion (i.e., <em>Gini Index</em> or <em>Information Gain</em>).

                              <center>
                                  <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/supervised_learning/dt_clf_train.png">
                            </center>
                          </p>
                        
                          <p align="justify">
                            After identifying the best classifier through Grid Search Cross-Validation, 
                              we evaluated its performance using the test dataset. The following screenshot 
                              presents the corresponding results. 
                            The complete implementation script is available on the GitHub page 
                            <a href="https://github.com/foroughshirinabkenar/traditional_ml_tutorial/blob/main/decision_tree_classification.ipynb" target="_blank">
                              Decision Tree Classifier</a>.

                            <center>
                              <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/supervised_learning/dt_clf_test.png">
                            </center>
                          </p>

                        <h3>Regressor</h3>
                          <p align="justify">
                              We developed a decision tree–based regressor. To this end, we implemented a 
                              <b>Decision Tree Regressor</b> using the <b>California Housing</b> dataset 
                              available in scikit-learn. The following screenshot shows the training 
                              (fitting) process of the regressor, where <b>Grid Search Cross-Validation</b> 
                              was employed to tune the optimal hyperparameters.

                              <center>
                                  <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/supervised_learning/dt_reg_train.png">
                            </center>
                          </p>

                        <p align="justify">
                            After training the regressor, we evaluated its performance on the test dataset. 
                            The following screenshot displays the corresponding results. The complete 
                            implementation script is available on the GitHub page 
                            <a href="https://github.com/foroughshirinabkenar/traditional_ml_tutorial/blob/main/decision_tree_regression.ipynb" target="_blank">
                              Decision Tree Regressor</a>.
                            
                            <center>
                              <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/supervised_learning/dt_reg_test.png">
                            </center>
                          </p>
                      
                      <h2>References</h2>
                      <p align="justify">
                        [1] F.Pedregosa, G.Varoquaux,A.Gramfort, V.Michel, B.Thirion, O.Grisel,M.Blondel, 
                        P.Prettenhofer, R.Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, 
                        M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine learning in Python,” 
                        Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.
                      </p>
                      <p align="justify">
                        [2] Misra Turp,
                        “How to implement decision tree from scratch with python,”
                        AssemblyAI, accessed: September 15, 2022,
                        <a href="https://www.youtube.com/watch?v=NxEHSAfFlK8" target="_blank">
                          https://www.youtube.com/watch?v=NxEHSAfFlK8</a>.
                      </p>
                    </header>
                    <section class="page__content" itemprop="text">
                        <footer class="page__meta"></footer>
                    </section>
                </div>
            </article>
        </div>
        <div class="page__footer">
            <footer> 
                <!-- start custom footer snippets --> 
                <!-- <a href="/sitemap/">Sitemap</a> end custom footer snippets -->
                <!-- <div class="page__footer-follow">
                    <ul class="social-icons">
                        <li><strong>Follow:</strong></li> -->
                        <!-- <li><a href="http://github.com/arghosh"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li> -->
                        <!-- <li><a href="https://arghosh.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li> -->
                    <!-- </ul> -->
                <!-- </div> -->
                <!-- <div class="page__footer-copyright">© 2020 Forough Shirin Abkenar. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>. -->
                <!-- </div> -->
            </footer>
        </div>
        <script src="https://foroughshirinabkenar.github.io/mysite/assets/js/main.min.js"></script> 
        <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-113060154-1', 'auto'); ga('send', 'pageview'); </script>
    </body>

</html>
