<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src='https://kit.fontawesome.com/a076d05399.js'></script>
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
        <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> -->
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
        <!-- begin SEO -->
        <title>RNN - Forough Shirin Abkenar</title>
        <meta property="og:locale" content="en-US">
        <meta property="og:site_name" content="RNN">
        <meta property="og:title" content="RNN">
        <link rel="canonical" href="https://foroughshirinabkenar.github.io/mysite/genAI.html">
        <meta property="og:url" content="https://foroughshirinabkenar.github.io/mysite/genAI.html">
        <meta property="og:description" content="RNN">
        <script async="" src="//www.google-analytics.com/analytics.js"></script>
        <script type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Aritra Ghosh", "url" : "https://foroughshirinabkenar.github.io", "sameAs" : null } </script>
        <!-- end SEO -->
        <!-- http://t.co/dKP3o1e -->
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script>
        <!-- For all browsers -->
        <link rel="stylesheet" href="https://foroughshirinabkenar.github.io/mysite/assets/css/main.css">
        <meta http-equiv="cleartype" content="on">
        <!-- start custom head snippets -->
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="https://foroughshirinabkenar.github.io/mysite/assets/css/academicons.css">
        <script type="text/x-mathjax-config;executed=true"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
        <script type="text/x-mathjax-config;executed=true"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML" async=""></script>
        <!-- end custom head snippets -->
        <style id="fit-vids-style">.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style>
        <script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
            .MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
            .MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
            .MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
            .MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
        </style>
        <style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
                #MathJax_About.MathJax_MousePost {outline: none}
                .MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
                .MathJax_MenuItem {padding: 2px 2em; background: transparent}
                .MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
                .MathJax_MenuActive .MathJax_MenuArrow {color: white}
                .MathJax_MenuArrow.RTL {left: .5em; right: auto}
                .MathJax_MenuCheck {position: absolute; left: .7em}
                .MathJax_MenuCheck.RTL {right: .7em; left: auto}
                .MathJax_MenuRadioCheck {position: absolute; left: 1em}
                .MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
                .MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
                .MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
                .MathJax_MenuDisabled {color: GrayText}
                .MathJax_MenuActive {background-color: Highlight; color: HighlightText}
                .MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
                .MathJax_ContextMenu:focus {outline: none}
                .MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
                #MathJax_AboutClose {top: .2em; right: .2em}
                .MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
                .MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
                .MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
                .MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
                .MathJax_MenuClose:hover span {background-color: #CCC!important}
                .MathJax_MenuClose:hover:focus {outline: none}
        </style>
        <style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
        </style>
        <style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
            .MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
        </style>
        <style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
            #MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
            #MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
            #MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
        </style>
        <style type="text/css">.MathJax_Preview {color: #888}
            #MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
            #MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
            .MathJax_Error {color: #CC0000; font-style: italic}
        </style>
        <style type="text/css">.MJXp-script {font-size: .8em}
            .MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
            .MJXp-bold {font-weight: bold}
            .MJXp-italic {font-style: italic}
            .MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-largeop {font-size: 150%}
            .MJXp-largeop.MJXp-int {vertical-align: -.2em}
            .MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
            .MJXp-display {display: block; text-align: center; margin: 1em 0}
            .MJXp-math span {display: inline-block}
            .MJXp-box {display: block!important; text-align: center}
            .MJXp-box:after {content: " "}
            .MJXp-rule {display: block!important; margin-top: .1em}
            .MJXp-char {display: block!important}
            .MJXp-mo {margin: 0 .15em}
            .MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
            .MJXp-denom {display: inline-table!important; width: 100%}
            .MJXp-denom > * {display: table-row!important}
            .MJXp-surd {vertical-align: top}
            .MJXp-surd > * {display: block!important}
            .MJXp-script-box > *  {display: table!important; height: 50%}
            .MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
            .MJXp-script-box > *:last-child > * {vertical-align: bottom}
            .MJXp-script-box > * > * > * {display: block!important}
            .MJXp-mphantom {visibility: hidden}
            .MJXp-munderover {display: inline-table!important}
            .MJXp-over {display: inline-block!important; text-align: center}
            .MJXp-over > * {display: block!important}
            .MJXp-munderover > * {display: table-row!important}
            .MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
            .MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
            .MJXp-mtr {display: table-row!important}
            .MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
            .MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
            .MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
            .MJXp-mlabeledtr {display: table-row!important}
            .MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
            .MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
            .MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
            .MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
            .MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
            .MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
            .MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
            .MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
            .MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
            .MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
            .MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
            .MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
            .MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
            .MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
        </style>
        <style>
          .table-wrap {overflow-x: auto;}
          #tab-eval-finetune {border-collapse: collapse; width: 100%; min-width: 720px; text-align: center;}
          #tab-eval-finetune caption {caption-side: top; font-weight: 600; margin-bottom: 0.5rem;}
          #tab-eval-finetune th,
          #tab-eval-finetune td {border: 1px solid #444; padding: 0.5rem 0.6rem; vertical-align: middle;}
          #tab-eval-finetune thead th {background: #f5f5f5;}
          /* Add cline effect under BLEU + ROUGE headers only */
          #tab-eval-finetune thead .cline-row th {border-top: none;}
          /* Draw a thick line under the second header row except the first column (PPL) */
          #tab-eval-finetune thead .cline-row th:not(:first-child) {border-bottom: 2px solid #000;}
        </style>
        <style>
          body {
            font-size: 16px;
            font-family: Arial, sans-serif;
          }
          h1 {
            font-size: 24;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
          h2 {
            font-size: 22;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
          h3 {
            font-size: 20px;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
          h4 {
            font-size: 18px;  /* adjust as you like */
            font-weight: bold;
            color: #333;
          }
        </style>
    </head>

    <body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
        <div id="MathJax_Message" style="display: none;"></div>
        <!--[if lt IE 9]>
            <div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
        <![endif]-->
        <div class="masthead">
            <div class="masthead__inner-wrap">
                <div class="masthead__menu">
                    <nav id="site-nav" class="greedy-nav"> 
                        <button class="hidden" count="0"><div class="navicon"></div></button>
                        <ul class="visible-links">
                            <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://foroughshirinabkenar.github.io/mysite/index.html">Forough Shirin Abkenar</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/publications.html">Publications</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/bio.html">Bio</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/traditional_ml.html">Traditional ML</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/genAI.html">Gen AI Projects</a></li>
                        </ul>
                        <ul class="hidden-links hidden"></ul>
                    </nav>
                </div>
            </div>
        </div>
        <div id="main" role="main">
            <div class="sidebar sticky">
                <div itemscope="" itemtype="http://schema.org/Person">
                    <div class="author__avatar"> <img src="https://foroughshirinabkenar.github.io/mysite/images/profile.jpeg" class="author__avatar" alt="Forough Shirin Abkenar"></div>
                    <div class="author__content">
                        <h3 class="author__name">Forough Shirin Abkenar</h3>
                        <p class="author__bio">Ph.D., Electrical Engineering and Computer Science</p>
                    </div>
                    <div class="author__urls-wrapper">
                        <button class="btn btn--inverse">Follow</button>
                        <ul class="author__urls social-icons">
                            <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> California, USA</li>
                            <li><a href="mailto:fshirina@uci.edu" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i> Email</a></li>
                            <!--<li><a href="https://foroughshirinabkenar.wixsite.com/mysite" target="_blank"><i class="fab fa-wix" aria-hidden="true"></i> Wix</a></li>
                            <li><a href="https://iasl.ics.uci.edu/people/forough-shirin-abkenar/" target="_blank">UCI</a></li>
                            <li><a href="https://www.researchgate.net/profile/Forough_Shirin_Abkenar2" target="_blank"><i class="fab fa-researchgate" style='color:green' aria-hidden="true"></i> ResearchGate</a></li>
                            -->
                            <li><a href="https://www.linkedin.com/in/forough-s-1460b2198" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
                            <li><a href="https://github.com/foroughshirinabkenar" target="_blank"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
                            <li><a href="https://scholar.google.com/citations?user=TQ0vI44AAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i> Google Scholar</a></li>
                            <li><a href="https://ieeexplore.ieee.org/author/37086113585" target="_blank"><img src="https://foroughshirinabkenar.github.io/mysite/images/logos/IEEE.jpg" style="width: 3em;"> IEEE</a></li>
                            <li><a href="https://www.webofscience.com/wos/author/record/AAA-7697-2019" target="_blank"><img src="https://foroughshirinabkenar.github.io/mysite/images/logos/wos.png" style="width: 1em;"> Web of Science</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <article class="page" itemscope="" itemtype="http://schema.org/CreativeWork">
                <meta itemprop="headline" content="RNN">
                <meta itemprop="description" content="RNN">
                <div class="page__inner-wrap">
                    <header>
                        <h1 class="page__title" itemprop="headline">Recurrent Neural Network</h1>
                        <p align="justify">
                          Recurrent Neural Networks (RNNs) are time-dependent architectures 
                          in which outputs from previous time steps participate in the prediction 
                          of the current output. Unlike MLPs and CNNs, which apply traditional 
                          backpropagation, RNNs employ <b>Backpropagation Through Time (BPTT)</b>, 
                          a variant designed to handle temporal dependencies. BPTT follows the 
                          same fundamental procedure as standard backpropagation, i.e., 
                          calculating errors from the output layer back to the input; yet, 
                          it propagates the <em>sum of errors over all time steps</em> that 
                          allows the network to learn from sequential dependencies. Figure 1 
                          illustrates the conceptual difference between an MLP and an RNN [1].

                          <figure style="display: flex; flex-direction: column; align-items: center;">
                              <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/deep_learning/rnn_vs_mlp.png"
                                  style="max-width: 50%; height: auto;"
                                />
                              <figcaption>Fig. 1: RNN vs. MLP. Left: MLP; Right: RNN [1].</figcaption>
                          </figure>
                        </p>

                        <p align="justify">
                          Figure 2 depicts the basic computational structure of an RNN unfolded 
                          across multiple time steps. At each time step \(t\), the model takes as 
                          input the current feature vector \(x_{t}\), the hidden state from the 
                          previous time step \(h_{t-1}\), and produces both an updated hidden 
                          state \(h_{t}\) and an output \(o_{t}\) [2].

                          <figure style="display: flex; flex-direction: column; align-items: center;">
                              <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/deep_learning/rnn.png"
                                  style="max-width: 60%; height: auto;"
                                />
                              <figcaption>Fig. 2: Building blocks of an RNN [2].</figcaption>
                          </figure>
                        </p>

                        <p align="justify">
                          The hidden state acts as the network's internal memory that carries 
                          temporal information across time. The hidden state at time step \(t\) 
                          is computed as [2]:
                        </p>

                        <p>
                          \[
                              h_{t} = \tanh(U x_{t} + V h_{t-1} + b_h),
                          \]
                        </p>

                        <p align="justify">
                          where \(U\) is the weight matrix associated with the input \(x_{t}\), 
                          \(V\) shows the weight matrix associated with the previous hidden 
                          state \(h_{t-1}\), and \(b_{h}\) represents bias term for the hidden layer.
                        </p>

                        <p align="justify">
                          Notabely, the RNN shares the same weights (\(U\), \(W\), and \(b_{h}\)) 
                          across all time steps, meaning that these parameters are time-invariant. 
                          This parameter sharing reduces model complexity and ensures consistent 
                          learning across temporal contexts [2].
                        </p>

                        <p align="justify">
                          Once the hidden state \(h_{t}\) is computed, the output at time \(t\) 
                          is generated using an activation function, commonly the sigmoid 
                          function \(\sigma(\cdot)\) [2]:
                        </p>

                        <p>
                          \[
                              o_{t} = \sigma(W_{o} h_{t} + b_{o}),
                          \]
                        </p>

                        <p align="justify">
                          where \(W\) and \(b_{o}\) denote the output-layer weights and bias, 
                          respectively. The term \(o_{t}\) represents the model's external 
                          output (used for tasks such as text generation, translation, or 
                          forecasting), while \(h_{t}\) serves as the internal output passed 
                          to the next time step \((t + 1)\) [2].
                        </p>

                        <p align="justify">
                          The RNN architecture offers both advantages and disadvantages [2]:

                          <ul>
                            <li>
                              <p align="justify">
                                <b>Advantages:</b>
                                <ul>
                                  <li>
                                    <p align="justify">
                                      Can handle variable-length sequential inputs.
                                    </p>
                                  </li>
                                  <li>
                                    <p align="justify">
                                      Maintains internal memory (hidden states) that captures 
                                      temporal dependencies.
                                    </p>
                                  </li>
                                  <li>
                                    <p align="justify">
                                      Shares parameters across time, reducing model size and 
                                      complexity.
                                    </p>
                                  </li>
                                  <li>
                                    <p align="justify">
                                      Well-suited for sequence-based tasks such as language 
                                      modeling, translation, speech recognition, and text 
                                      summarization.
                                    </p>
                                  </li>
                                </ul>
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>Disadvantages:</b>
                                <ul>
                                  <li>
                                    <p align="justify">
                                      Prone to the <em>vanishing</em> and 
                                      <em>exploding gradient</em> problems during training.
                                    </p>
                                  </li>
                                  <li>
                                    <p align="justify">
                                      Struggles with long-term dependencies, making it 
                                      less effective for tasks requiring long-range context.
                                    </p>
                                  </li>
                                  <li>
                                    <p align="justify">
                                      Sequential computation limits parallelization, leading 
                                      to slower training compared to feed-forward architectures.
                                    </p>
                                  </li>
                                </ul>
                              </p>
                            </li>
                          </ul>
                        </p>

                        <h2>Long Short-Term Memory</h2>
                        <p align="justify">
                          As mentioned earlier, RNNs are prone to the gradient vanishing problem. 
                          The Long Short-Term Memory (LSTM) architecture addresses this issue by 
                          introducing a long-term memory mechanism (see Fig. 3) [3-5].

                          <figure style="display: flex; flex-direction: column; align-items: center;">
                              <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/deep_learning/lstm_vs_rnn.png"
                                  style="max-width: 40%; height: auto;"
                                />
                              <figcaption>Fig. 3: LSTM vs RNN. Left: RNN; Right: LSTM [3].</figcaption>
                          </figure>
                        </p>

                        <p align="justify">
                          LSTMs maintain both short-term and long-term states across time steps. 
                          Figure 4 illustrates the architecture of an LSTM, which consists of 
                          three gates: <em>forget gate</em>, <em>input gate</em>, and 
                          <em>output gate</em> [4].

                          <figure style="display: flex; flex-direction: column; align-items: center;">
                              <img src="https://foroughshirinabkenar.github.io/mysite/images/traditional_ml/deep_learning/lstm.png"
                                  style="max-width: 80%; height: auto;"
                                />
                              <figcaption>Fig. 4: Building blocks of an LSTM [4].</figcaption>
                          </figure>
                        </p>

                        <p align="justify">
                          The forget gate allows the model to selectively discard irrelevant 
                          information from the past. Specifically, the previous hidden state, 
                          \(h_{t-1}\), and the current input, \(x_{t}\), are processed to 
                          generate a forget vector, \(f_{t}\), that controls how much of the 
                          previous cell state \(C_{t-1}\) should be retained [4]:
                        </p>

                        <p>
                          \[
                              f_{t} = \sigma\Big(W_{f} \cdot [h_{t-1}, x_{t}] + b_{f}\Big),
                          \]
                        </p>

                        <p align="justify">
                          where \(W_{f}\) and \(b_{f}\) represent the weights and bias of 
                          the forget gate, respectively. The updated cell state is then 
                          partially preserved as \(C_{t-1} \odot f_{t}\) [4].
                        </p>
                      
                        <p align="justify">
                          The input gate determines what new information should be added 
                          to the cell state. Both \(h_{t-1}\) and \(x_{t}\) are passed 
                          through a <em>sigmoid</em> layer and a \(\tanh\) layer to 
                          generate candidate updates [4]:
                        </p>

                        <p>
                          \[
                              \begin{split}
                                  i_{t} &= \sigma\Big(W_{i} \cdot [h_{t-1}, x_{t}] + b_{i}\Big),\\
                                  \hat{C}_{t} &= \tanh\Big(W_{c} \cdot [h_{t-1}, x_{t}] + b_{c}\Big),
                              \end{split}
                          \]
                        </p>

                        <p align="justify">
                          where \(i_{t}\) represents the input modulation gate, and \(\hat{C}_{t}\) 
                          represents the candidate cell state. The new cell state \(C_{t}\) is then 
                          updated as follows [4]:
                        </p>
                      
                        <p>
                          \[
                              C_{t} = f_{t} \odot C_{t-1} + i_{t} \odot \hat{C}_{t}
                          \]
                        </p>

                        <p align="justify">
                          Finally, the output gate controls what part of the cell state should be 
                          output at each time step. The gate first computes an activation \(o_{t}\), 
                          then multiplies it with the \(\tanh\)-transformed cell state to obtain 
                          the new hidden state \(h_{t}\) [4]:
                        </p>

                        <p>
                          \[
                              \begin{split}
                                  o_{t} &= \sigma\Big(W_{o} \cdot [h_{t-1}, x_{t}] + b_{o}\Big),\\
                                  h_{t} &= o_{t} \odot \tanh(C_{t}),
                              \end{split}
                          \]
                        </p>

                        <p align="justify">
                          where \(W_{o}\) and \(b_{o}\) denote the weights and bias terms for 
                          the output gate. In summary, LSTMs effectively mitigate the vanishing 
                          gradient problem by maintaining a stable cell state, enabling the model 
                          to capture long-range temporal dependencies [4].
                        </p>
                      
                      <h2>References</h2>
                      <p align="justify">
                        [1] Jeff Shepard,
                        “How does a recurrent neural network (RNN) remember?,”
                        Microcontrollertips, accessed: May 8, 2024,
                        <a href="https://www.microcontrollertips.com/how-does-a-recurrent-neural-network-remember/" target="_blank">
                          https://www.microcontrollertips.com/how-does-a-recurrent-neural-network-remember/</a>.
                      </p>
                      <p align="justify">
                        [2] Cole Stryker,
                        “What is a recurrent neural network (RNN)?,”
                        International Business Machines (IBM), accessed: 2025,
                        <a href="https://www.ibm.com/think/topics/recurrent-neural-networks" target="_blank">
                          https://www.ibm.com/think/topics/recurrent-neural-networks</a>.
                      </p>
                      <p align="justify">
                        [3] Robail Yasrab <em>et al.</em>,
                        "PhenomNet: Bridging Phenotype-Genotype Gap: A CNN-LSTM Based Automatic Plant Root Anatomization System,"
                        bioRxiv, accessed: 2020.
                      </p>
                      <p align="justify">
                        [4] GeeksforGeeks,
                        “What is LSTM - Long Short Term Memory?,”
                        GeeksforGeeks, accessed: October 7, 2025,
                        <a href="https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/" target="_blank">
                          https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/</a>.
                      </p>
                      <p align="justify">
                        [4] Nvidia,
                        “Long Short-Term Memory (LSTM),”
                        Nvidia, accessed: 2025,
                        <a href="https://developer.nvidia.com/discover/lstm" target="_blank">
                          https://developer.nvidia.com/discover/lstm</a>.
                      </p>
                    </header>
                    <section class="page__content" itemprop="text">
                        <footer class="page__meta"></footer>
                    </section>
                </div>
            </article>
        </div>
        <div class="page__footer">
            <footer> 
                <!-- start custom footer snippets --> 
                <!-- <a href="/sitemap/">Sitemap</a> end custom footer snippets -->
                <!-- <div class="page__footer-follow">
                    <ul class="social-icons">
                        <li><strong>Follow:</strong></li> -->
                        <!-- <li><a href="http://github.com/arghosh"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li> -->
                        <!-- <li><a href="https://arghosh.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li> -->
                    <!-- </ul> -->
                <!-- </div> -->
                <!-- <div class="page__footer-copyright">© 2020 Forough Shirin Abkenar. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>. -->
                <!-- </div> -->
            </footer>
        </div>
        <script src="https://foroughshirinabkenar.github.io/mysite/assets/js/main.min.js"></script> 
        <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-113060154-1', 'auto'); ga('send', 'pageview'); </script>
    </body>

</html>
