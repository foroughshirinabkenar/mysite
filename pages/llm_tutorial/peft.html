<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src='https://kit.fontawesome.com/a076d05399.js'></script>
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
        <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> -->
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
        <!-- begin SEO -->
        <title>PEFT - Forough Shirin Abkenar</title>
        <meta property="og:locale" content="en-US">
        <meta property="og:site_name" content="PEFT">
        <meta property="og:title" content="PEFT">
        <link rel="canonical" href="https://foroughshirinabkenar.github.io/mysite/llm.html">
        <meta property="og:url" content="https://foroughshirinabkenar.github.io/mysite/llm.html">
        <meta property="og:description" content="PEFT">
        <script async="" src="//www.google-analytics.com/analytics.js"></script>
        <script type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Aritra Ghosh", "url" : "https://foroughshirinabkenar.github.io", "sameAs" : null } </script>
        <!-- end SEO -->
        <!-- http://t.co/dKP3o1e -->
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script>
        <!-- For all browsers -->
        <link rel="stylesheet" href="https://foroughshirinabkenar.github.io/mysite/assets/css/main.css">
        <meta http-equiv="cleartype" content="on">
        <!-- start custom head snippets -->
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="https://foroughshirinabkenar.github.io/mysite/assets/css/academicons.css">
        <script type="text/x-mathjax-config;executed=true"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
        <script type="text/x-mathjax-config;executed=true"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML" async=""></script>
        <!-- end custom head snippets -->
        <style id="fit-vids-style">.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style>
        <script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
            .MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
            .MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
            .MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
            .MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
        </style>
        <style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
                #MathJax_About.MathJax_MousePost {outline: none}
                .MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
                .MathJax_MenuItem {padding: 2px 2em; background: transparent}
                .MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
                .MathJax_MenuActive .MathJax_MenuArrow {color: white}
                .MathJax_MenuArrow.RTL {left: .5em; right: auto}
                .MathJax_MenuCheck {position: absolute; left: .7em}
                .MathJax_MenuCheck.RTL {right: .7em; left: auto}
                .MathJax_MenuRadioCheck {position: absolute; left: 1em}
                .MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
                .MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
                .MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
                .MathJax_MenuDisabled {color: GrayText}
                .MathJax_MenuActive {background-color: Highlight; color: HighlightText}
                .MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
                .MathJax_ContextMenu:focus {outline: none}
                .MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
                #MathJax_AboutClose {top: .2em; right: .2em}
                .MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
                .MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
                .MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
                .MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
                .MathJax_MenuClose:hover span {background-color: #CCC!important}
                .MathJax_MenuClose:hover:focus {outline: none}
        </style>
        <style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
        </style>
        <style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
            .MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
        </style>
        <style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
            #MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
            #MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
            #MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
        </style>
        <style type="text/css">.MathJax_Preview {color: #888}
            #MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
            #MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
            .MathJax_Error {color: #CC0000; font-style: italic}
        </style>
        <style type="text/css">.MJXp-script {font-size: .8em}
            .MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
            .MJXp-bold {font-weight: bold}
            .MJXp-italic {font-style: italic}
            .MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
            .MJXp-largeop {font-size: 150%}
            .MJXp-largeop.MJXp-int {vertical-align: -.2em}
            .MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
            .MJXp-display {display: block; text-align: center; margin: 1em 0}
            .MJXp-math span {display: inline-block}
            .MJXp-box {display: block!important; text-align: center}
            .MJXp-box:after {content: " "}
            .MJXp-rule {display: block!important; margin-top: .1em}
            .MJXp-char {display: block!important}
            .MJXp-mo {margin: 0 .15em}
            .MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
            .MJXp-denom {display: inline-table!important; width: 100%}
            .MJXp-denom > * {display: table-row!important}
            .MJXp-surd {vertical-align: top}
            .MJXp-surd > * {display: block!important}
            .MJXp-script-box > *  {display: table!important; height: 50%}
            .MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
            .MJXp-script-box > *:last-child > * {vertical-align: bottom}
            .MJXp-script-box > * > * > * {display: block!important}
            .MJXp-mphantom {visibility: hidden}
            .MJXp-munderover {display: inline-table!important}
            .MJXp-over {display: inline-block!important; text-align: center}
            .MJXp-over > * {display: block!important}
            .MJXp-munderover > * {display: table-row!important}
            .MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
            .MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
            .MJXp-mtr {display: table-row!important}
            .MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
            .MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
            .MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
            .MJXp-mlabeledtr {display: table-row!important}
            .MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
            .MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
            .MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
            .MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
            .MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
            .MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
            .MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
            .MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
            .MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
            .MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
            .MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
            .MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
            .MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
            .MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
        </style>
        <style>
          .table-wrap {overflow-x: auto;}
          #tab-eval-finetune {border-collapse: collapse; width: 100%; min-width: 720px; text-align: center;}
          #tab-eval-finetune caption {caption-side: top; font-weight: 600; margin-bottom: 0.5rem;}
          #tab-eval-finetune th,
          #tab-eval-finetune td {border: 1px solid #444; padding: 0.5rem 0.6rem; vertical-align: middle;}
          #tab-eval-finetune thead th {background: #f5f5f5;}
          /* Add cline effect under BLEU + ROUGE headers only */
          #tab-eval-finetune thead .cline-row th {border-top: none;}
          /* Draw a thick line under the second header row except the first column (PPL) */
          #tab-eval-finetune thead .cline-row th:not(:first-child) {border-bottom: 2px solid #000;}
        </style>
    </head>

    <body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
        <div id="MathJax_Message" style="display: none;"></div>
        <!--[if lt IE 9]>
            <div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
        <![endif]-->
        <div class="masthead">
            <div class="masthead__inner-wrap">
                <div class="masthead__menu">
                    <nav id="site-nav" class="greedy-nav"> 
                        <button class="hidden" count="0"><div class="navicon"></div></button>
                        <ul class="visible-links">
                            <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://foroughshirinabkenar.github.io/mysite/index.html">Forough Shirin Abkenar</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/publications.html">Publications</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/bio.html">Bio</a></li>
                            <li class="masthead__menu-item"><a href="https://foroughshirinabkenar.github.io/mysite/llm.html">LLM Projects</a></li>
                        </ul>
                        <ul class="hidden-links hidden"></ul>
                    </nav>
                </div>
            </div>
        </div>
        <div id="main" role="main">
            <div class="sidebar sticky">
                <div itemscope="" itemtype="http://schema.org/Person">
                    <div class="author__avatar"> <img src="https://foroughshirinabkenar.github.io/mysite/images/profile.jpeg" class="author__avatar" alt="Forough Shirin Abkenar"></div>
                    <div class="author__content">
                        <h3 class="author__name">Forough Shirin Abkenar</h3>
                        <p class="author__bio">Ph.D., Electrical Engineering and Computer Science</p>
                    </div>
                    <div class="author__urls-wrapper">
                        <button class="btn btn--inverse">Follow</button>
                        <ul class="author__urls social-icons">
                            <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> California, USA</li>
                            <li><a href="mailto:fshirina@uci.edu" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i> Email</a></li>
                            <!--<li><a href="https://foroughshirinabkenar.wixsite.com/mysite" target="_blank"><i class="fab fa-wix" aria-hidden="true"></i> Wix</a></li>
                            <li><a href="https://iasl.ics.uci.edu/people/forough-shirin-abkenar/" target="_blank">UCI</a></li>
                            <li><a href="https://www.researchgate.net/profile/Forough_Shirin_Abkenar2" target="_blank"><i class="fab fa-researchgate" style='color:green' aria-hidden="true"></i> ResearchGate</a></li>
                            -->
                            <li><a href="https://www.linkedin.com/in/forough-s-1460b2198" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
                            <li><a href="https://github.com/foroughshirinabkenar" target="_blank"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
                            <li><a href="https://scholar.google.com/citations?user=TQ0vI44AAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i> Google Scholar</a></li>
                            <li><a href="https://ieeexplore.ieee.org/author/37086113585" target="_blank"><img src="https://foroughshirinabkenar.github.io/mysite/images/logos/IEEE.jpg" style="width: 3em;"> IEEE</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <article class="page" itemscope="" itemtype="http://schema.org/CreativeWork">
                <meta itemprop="headline" content="PEFT">
                <meta itemprop="description" content="PEFT">
                <div class="page__inner-wrap">
                    <header>
                        <h1 class="page__title" itemprop="headline">Parameter-efficinet Fine-tuning</h1>
                        <p align="justify">
                          Pre-trained large-language models (LLMs) own a large set of parameters. 
                          Although these models achieve strong overall performance, they often 
                          struggle with tasks in which the data distribution differs significantly 
                          from their training set. Fine-tuning, i.e., the process of updating the 
                          parameters of a pre-trained model by training the model on a dataset 
                          specific to the task (see 
                          <a href="https://foroughshirinabkenar.github.io/mysite/pages/llm_tutorial/fine_tuning.html" target="_blank">Fine-tuning</a>), 
                          is a crucial technique to address this limitation [1].
                        </p>

                        <p align="justify">
                          Although fine-tuning adapts the model more effectively to specific tasks, 
                          pre-trained models often contain a large number of parameters, which 
                          reduces the efficiency of fine-tuning, particularly in terms of inference 
                          speed. To address this challenge, parameter-efficient fine-tuning (PEFT) [2] 
                          is employed. PEFT preserves the overall model architecture while updating 
                          only a small subset of parameters, thereby reducing computational overhead 
                          and improving both training efficiency and inference performance.
                        </p>

                        <p align="justify">
                          To this end, PEFT freezes the majority of the pre-trained parameters and 
                          layers, introducing only a small number of trainable parameters, known as 
                          adapters, into the final layers of the model for the task at hand. This 
                          approach allows fine-tuned models to retain the knowledge acquired during 
                          pre-training while efficiently specializing in their respective downstream 
                          tasks [2].
                        </p>

                      <h2>Low-rank Adaptation</h2>
                        <p align="justify">
                          Low-rank adaptation (LoRA) is an efficient PEFT technique that leverages 
                          low-rank decomposition to reduce the number of trainable parameters. 
                          Figure 1 shows the overall workflow of LoRA wherein LoRA freezes the 
                          high-dimensional pre-trained weight matrix and decomposes that into two 
                          lower-rank matrices, <em>A</em> and <em>B</em>. As a result, 
                          rather than the high-dimensional pre-trained weight matrix, the two 
                          low-rank matrices are updated during fine-tuning to capture task-specific 
                          adaptations. After training, these matrices are merged with the original 
                          weights to form an updated parameter matrix. This results in efficient 
                          training without modifying most of the pre-trained parameters [3].
                          
                          <figure style="display: flex; flex-direction: column; align-items: center;">
                            <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/lora.png"
                                style="max-width: 50%; height: auto;"
                              />
                            <figcaption>Fig. 1: Overall workflow of LoRA.</figcaption>
                          </figure>
                        </p>
                      
                      <h2>Implementation</h2>
                      <p align="justify">
                        In this section, we fine-tune the <b>GPT-2</b> model. 
                        The complete implementation script is available on
                        <a href="https://github.com/foroughshirinabkenar/llm_tutorial/blob/main/04_llm_basics_peft_lora.ipynb" target="_blank">PEFT_LoRA</a>.
                      </p>
                      
                      <p align="justify">
                        The fundamental components in fine-tuning a model using Hugging Face application 
                        programming interface (API) [4] are <em>tokenizer</em>, <em>foundation model</em>, 
                        <em>training arguments, (hyperparameters)</em>, and <em>data collator</em>, and 
                        <em>trainer API</em>. We also need to import PEFT-related libraries into the program.
                        
                        <center>
                          <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/libraries.png"/>
                        </center>
                      </p>

                      <p align="justify">
                        Tokenizer is responsible for tokenizing the inputs into tokens and encoding them to 
                        the corresponding token IDs. Each foundation model has its own tokenizer, developed 
                        based on the pre-defined vocabulary (or dictionary) for the model. For loading both 
                        tokenizer and model, we define a checkpoint w.r.t. the foundation model we are going 
                        to exploit for fine-tuning. Here, we have <em>model_name = "gpt2"</em>.
                        <center>
                          <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/tokenizer.png"/>
                        </center>
                      </p>

                      <p align="justify">
                        Truncation and padding are essential configurations that must be specified for the 
                        tokenizer. To achieve this, a dedicated function (e.g., <em>tokenization_fn</em>) 
                        is typically defined to set these parameters accordingly. Within this function, the 
                        <em>max_length</em> parameter plays a key role, as it determines the sequence length 
                        used for both truncation and padding.
                        
                        <center>
                          <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/tokenizer_fn.png"/>
                        </center>
                      </p>

                      <p align="justify">
                        Next, we need to load the model from the pre-defined checkpoint. After loading the model, 
                        we define the LoRA configuration and modify the model accordingly.
                        
                        <center>
                          <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/model.png"/>
                        </center>
                      </p>

                      <p align="justify">
                        For fine-tuning the loaded model, training arguments must be properly defined. In this regard, we have

                        <ul>
                            <li>
                              <p align="justify">
                                <b>output_dir:</b> the directory where checkpoints are saved.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>eval_strategy:</b> the evaluation strategy.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>per_device_train/eval_batch_size:</b> keeps virtual random access memory (VRAM) usage low.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>gradient_accumulation_steps:</b> simulates larger effective batch size without increasing VRAM.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>num_train_epochs:</b> number of passes over the dataset for fine-tuning.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>learning_rate:</b> learning rate.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>logging_steps:</b> number of steps for logging loss.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>save_steps:</b> number of steps to save checkpoints.
                              </p>
                            </li>
                            <li>
                              <p align="justify">
                                <b>label_names:</b> labels in the dataset.
                              </p>
                            </li>
                       </ul>
                        
                        <center>
                          <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/args.png"/>
                        </center>
                      </p>

                      <p align="justify">
                        The data collator handles padding and batching. It takes a list 
                        of individual data samples and organizes them into a single and 
                        consistent batch using padding, creating attention masks, and 
                        handling special tokens.
                        
                        <center>
                          <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/collator.png"/>
                        </center>
                      </p>

                      <p align="justify">
                        Finally, we define the <em>trainer</em> and perform the fine-tuning. We also record the training time.
                        
                        <center>
                          <img src="https://foroughshirinabkenar.github.io/mysite/images/llm_tutorial/peft/trainer.png"/>
                        </center>
                      </p>
                      
                      <h3>Evaluation</h3>
                      <p align="justify">
                        To evaluate the performance of the fine-tuned model, we exploit perplexity, 
                        bilingual evaluation understudy (BLEU) [5], and recall-oriented understudy for 
                        gisting evaluation (ROUGE) [6].

                        <ul>
                          <li>
                            <p align="justify">
                              <b>Perplexity:</b> it measures the model's uncertainty; lower perplexity 
                              implies that the model assigns higher probability to the actual next word 
                              in the sequence, resulting a more confident and accurate model.
                            </p>
                          </li>
                          <li>
                            <p align="justify">
                              <b>BLEU:</b> this metric evaluates the quality of machine-translated text 
                              by comparing it to human-created reference translations. To this end, it 
                              computes the overlap of n-grams between the machine-translated text and 
                              the reference translation.
                            </p>
                          </li>
                          <li>
                            <p align="justify">
                              <b>ROUGE:</b> it calculates precision, recall, and F1 score to quantify 
                              the overlap (n-grams) in words, phrases, and sequences between the 
                              machine-translated text and the reference translation.
                            </p>
                          </li>
                        </ul>
                      </p>
                      <p align="justify">
                        Table I indicates the corresponding results. It is worth noting that achieving 
                        a highly efficient model requires fine-tuning on an appropriately selected 
                        dataset with a sufficient number of samples. However, the objective of this 
                        project is limited to reviewing the fine-tuning mechanisms in LLMs. Consequently, 
                        the resulting model performance may not be fully optimized.
                      </p>
                      <div class="table-wrap">
                        <table id="tab-eval-finetune">
                          <caption>Table I. Performance evaluation of the fine-tuned LoRA model.</caption>
                          <thead>
                            <tr>
                              <th style="text-align: center; vertical-align: middle;" rowspan="2" scope="col">PPL</th>
                              <th style="text-align: center; vertical-align: middle;" colspan="5" scope="colgroup">BLEU</th>
                              <th style="text-align: center; vertical-align: middle;" colspan="4" scope="colgroup">ROUGE</th>
                              <th style="text-align: center; vertical-align: middle;" rowspan="2" scope="col">Time (s)</th>
                            </tr>
                            <tr>
                              <th style="text-align: center; vertical-align: middle;" scope="col">bleu</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">unigrams</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">bigrams</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">trigrams</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">quadgrams</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">rouge1</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">rouge2</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">rougeL</th>
                              <th style="text-align: center; vertical-align: middle;" scope="col">rougeLSum</th>
                            </tr>
                          </thead>
                          <tbody>
                            <tr>
                              <td style="text-align: center; vertical-align: middle;">65.4614</td>
                              <td style="text-align: center; vertical-align: middle;">0.6626</td>
                              <td style="text-align: center; vertical-align: middle;">0.6663</td>
                              <td style="text-align: center; vertical-align: middle;">0.6638</td>
                              <td style="text-align: center; vertical-align: middle;">0.6612</td>
                              <td style="text-align: center; vertical-align: middle;">0.6591</td>
                              <td style="text-align: center; vertical-align: middle;">0.7467</td>
                              <td style="text-align: center; vertical-align: middle;">0.6738</td>
                              <td style="text-align: center; vertical-align: middle;">0.7466</td>
                              <td style="text-align: center; vertical-align: middle;">0.7473</td>
                              <td style="text-align: center; vertical-align: middle;">83.3375</td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                      
                      <h2>References</h2>
                      <p align="justify">
                        [1] M. R. J, K. VM, H. Warrier, and Y. Gupta, “Fine tuning llm for enterprise: Practical guidelines and
                            recommendations,” 2024, <a href="https://arxiv.org/abs/2404.10779" target="_blank">https://arxiv.org/abs/2404.10779</a>.
                      </p>
                      <p align="justify">
                        [2] C. Stryker and I. Belcic, “What is parameter-efficient fine-tuning (peft)?”
                        International Business Machines (IBM), accessed: Aug. 15, 2024,
                            <a href="https://www.ibm.com/think/topics/ parameter-efficient-fine-tuning" target="_blank">https://doi.org/10.3115/1073083.1073135</a>.
                      </p>
                      <p align="justify">
                        [3] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “Lora: Low-rank adaptation of large language models,”
                        2021, <a href="https://arxiv.org/abs/2106.09685" target="_blank">https://arxiv.org/abs/2106.09685</a>.
                      </p>
                      <p align="justify">
                        [4] Hugging Face, <a href="http://huggingface.co/" target="_blank">http://huggingface.co/</a>
                      </p>
                      <p align="justify">
                        [5] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “Bleu: a method for automatic evaluation of
                            machine translation,” in Proceedings of the 40th Annual Meeting on Association for Computational
                            Linguistics. USA: Association for Computational Linguistics, 2002, p. 311–318,
                            <a href="https://doi.org/10.3115/1073083.1073135" target="_blank">https://doi.org/10.3115/1073083.1073135</a>.
                      </p>
                      <p align="justify">
                        [6] C.-Y. Lin, “Rouge: A package for automatic evaluation of summaries,” in Annual Meeting of the Association for
                            Computational Linguistics, 2004, <a href="https://api.semanticscholar.org/CorpusID:964287" target="_blank">https://api.semanticscholar.org/CorpusID:964287</a>.
                      </p>
                    </header>
                    <section class="page__content" itemprop="text">
                        <footer class="page__meta"></footer>
                    </section>
                </div>
            </article>
        </div>
        <div class="page__footer">
            <footer> 
                <!-- start custom footer snippets --> 
                <!-- <a href="/sitemap/">Sitemap</a> end custom footer snippets -->
                <!-- <div class="page__footer-follow">
                    <ul class="social-icons">
                        <li><strong>Follow:</strong></li> -->
                        <!-- <li><a href="http://github.com/arghosh"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li> -->
                        <!-- <li><a href="https://arghosh.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li> -->
                    <!-- </ul> -->
                <!-- </div> -->
                <!-- <div class="page__footer-copyright">© 2020 Forough Shirin Abkenar. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>. -->
                <!-- </div> -->
            </footer>
        </div>
        <script src="https://foroughshirinabkenar.github.io/mysite/assets/js/main.min.js"></script> 
        <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-113060154-1', 'auto'); ga('send', 'pageview'); </script>
    </body>

</html>
